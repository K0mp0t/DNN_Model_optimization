{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9xs6SOgzjO1",
        "outputId": "eaa3b6e5-80f9-4dc1-9624-8abc2bc7d569",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/dnn_model_optimization')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics torchinfo onnxruntime-gpu onnx onnxsim onnxoptimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBT8E9on1lS5",
        "outputId": "e3d0069e-9f93-497f-871b-da380d9b86ea",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.4/153.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m678.1/678.1 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from utils.torch_helpers import train_model, validate_model, warmup_torch_model, ctc_loss_log_differentiable_torch\n",
        "from utils.torch_model import CRNN\n",
        "from utils.data import decode_texts, load_data, OCRDataset\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchinfo import summary\n",
        "from torchmetrics.text import CharErrorRate\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "from itertools import groupby\n",
        "\n",
        "\n",
        "((train_imgs, train_abits), train_labels), ((val_imgs, val_abits), val_labels), alphabet = load_data('/content/drive/MyDrive/dnn_model_optimization/data', split=True)\n",
        "\n",
        "train_dataset = OCRDataset(train_imgs, train_abits, train_labels)\n",
        "val_dataset = OCRDataset(val_imgs, val_abits, val_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128)"
      ],
      "metadata": {
        "id": "XCXIq6wRhA75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = CRNN(len(alphabet))\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields_.pt', map_location=torch.device(device)))\n",
        "summary(model, input_size=[(32, 1, 32, 400), (32, 50, 2)], device=device, depth=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_HjpWxB1w37",
        "outputId": "9f54e95f-1b76-48c5-81a6-cf5ad8e9358e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "CRNN                                     [32, 50, 46]              --\n",
              "├─Sequential: 1-1                        [32, 256, 1, 50]          425,856\n",
              "├─LSTM: 1-2                              [32, 50, 256]             528,384\n",
              "├─LSTM: 1-3                              [32, 50, 256]             526,336\n",
              "├─Sequential: 1-4                        [32, 50, 46]              11,822\n",
              "==========================================================================================\n",
              "Total params: 1,492,398\n",
              "Trainable params: 1,492,398\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 7.49\n",
              "==========================================================================================\n",
              "Input size (MB): 1.65\n",
              "Forward/backward pass size (MB): 413.47\n",
              "Params size (MB): 5.97\n",
              "Estimated Total Size (MB): 421.09\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Original model before warmup: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, alphabet, device=device)])))\n",
        "warmup_torch_model(model, [(32, 1, 32, 400), (32, 50, 2)], device)\n",
        "print('Original model after warmup: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, alphabet, device=device)])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bggFBKwM2HHf",
        "outputId": "d91c1ace-20a1-4d9e-f475-60570005aa04",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original model before warmup:  {'batch_time': 0.003233, 'loss': 14.042188, 'metric': 0.049073}\n",
            "Original model after warmup:  {'batch_time': 0.002996, 'loss': 14.042188, 'metric': 0.049073}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model conversion to ONNX format and measurements\n",
        "1. I had to replace string value in padding='same' to integer padding=1 so onnx exporter could work properely\n",
        "2. I had to specify dynamic_axes argument due to the presence LSTM"
      ],
      "metadata": {
        "id": "srJAtdUh2pNg",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1, x2 = next(iter(train_loader))[0]\n",
        "\n",
        "model.to(device)\n",
        "torch.onnx.export(model, (x1[0].unsqueeze(0).to(device), x2[0].unsqueeze(0).to(device)),\n",
        "                  \"/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields.onnx\",\n",
        "                  input_names=['image_data', 'field_data'], output_names=['output'],\n",
        "                  dynamic_axes={'image_data' : {0 : 'batch_size'},\n",
        "                                'field_data' : {0 : 'batch_size'},\n",
        "                                'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4nDuA798GbH",
        "outputId": "980b54b7-c146-4b18-a086-bb1445b59db5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/symbolic_opset9.py:4661: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m onnxoptimizer \"/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields.onnx\" \"/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields_opt.onnx\"\n",
        "!onnxsim \"/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields_opt.onnx\" \"/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields_opt.onnx\""
      ],
      "metadata": {
        "id": "_X4krU3PPO3T",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a61be4-548a-47b5-8c49-7ecb1372df4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mYour model contains \"Tile\" ops or/and \"ConstantOfShape\" ops. Folding these ops can make the \u001b[0m\n",
            "\u001b[1;35msimplified model much larger. If it is not expected, please specify \"--no-large-tensor\" (which will \u001b[0m\n",
            "\u001b[1;35mlose some optimization chances)\u001b[0m\n",
            "Simplifying\u001b[33m...\u001b[0m\n",
            "Finish! Here is the difference:\n",
            "┏━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
            "│ Add                │ 1              │ 1                │\n",
            "│ BatchNormalization │ 5              │ 5                │\n",
            "│ Concat             │ 3              │ 3                │\n",
            "│ Constant           │ 43             │ 43               │\n",
            "│ ConstantOfShape    │ 2              │ 2                │\n",
            "│ Conv               │ 5              │ 5                │\n",
            "│ Gather             │ 2              │ 2                │\n",
            "│ LSTM               │ 2              │ 2                │\n",
            "│ LeakyRelu          │ 5              │ 5                │\n",
            "│ MatMul             │ 1              │ 1                │\n",
            "│ MaxPool            │ 5              │ 5                │\n",
            "│ Shape              │ 2              │ 2                │\n",
            "│ Softmax            │ 1              │ 1                │\n",
            "│ Squeeze            │ 3              │ 3                │\n",
            "│ Transpose          │ 4              │ 4                │\n",
            "│ Unsqueeze          │ 2              │ 2                │\n",
            "│ Model Size         │ 5.7MiB         │ 5.7MiB           │\n",
            "└────────────────────┴────────────────┴──────────────────┘\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import groupby\n",
        "\n",
        "sess = ort.InferenceSession(\"/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields_opt.onnx\", providers=[\"CUDAExecutionProvider\"])\n",
        "output_names = [output.name for output in sess.get_outputs()]\n",
        "\n",
        "batch_size = 128\n",
        "n = batch_size - val_imgs.shape[0] % batch_size\n",
        "\n",
        "val_imgs_batched = val_imgs.copy()\n",
        "val_abits_batched = val_abits.copy()\n",
        "\n",
        "val_imgs_batched = np.concatenate([val_imgs_batched, val_imgs_batched[:n]], axis=0)\n",
        "val_abits_batched = np.concatenate([val_abits_batched, val_abits_batched[:n]], axis=0)\n",
        "\n",
        "val_imgs_batched = np.expand_dims(val_imgs_batched, 1).astype('float32').reshape(batch_size, -1, 1, 32, 400)\n",
        "val_abits_batched = val_abits_batched.astype('float32').reshape(batch_size, -1, 50, 2)\n",
        "\n",
        "runs = 10\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "for i in range(runs):\n",
        "    y_pred = list()\n",
        "    for i in range(val_imgs_batched.shape[0]):\n",
        "        sess.run(output_names, {'image_data': val_imgs_batched[i], 'field_data': val_abits_batched[i]})\n",
        "time_spent = (time.time()-start) / val_imgs_batched.shape[0] / runs\n",
        "\n",
        "y_pred = list()\n",
        "for i in range(1, val_imgs.shape[0] // batch_size + 2):\n",
        "    y_pred.append(sess.run(output_names, {'image_data': np.expand_dims(val_imgs, 1).astype('float32')[(i-1)*batch_size: i*batch_size],\n",
        "                                          'field_data': val_abits[(i-1)*batch_size: i*batch_size].astype('float32')})[0])\n",
        "y_pred = np.concatenate(y_pred)\n",
        "\n",
        "input_lengths = torch.full((y_pred.shape[0],), y_pred.shape[1]).to('cpu')\n",
        "val_labels = torch.LongTensor(val_labels).to('cpu')\n",
        "target_lengths = torch.sum(val_labels != 0, axis=1)\n",
        "\n",
        "criterion = ctc_loss_log_differentiable_torch\n",
        "metric = CharErrorRate()\n",
        "\n",
        "loss = criterion(torch.log(torch.FloatTensor(y_pred).to('cpu')), val_labels, input_lengths, target_lengths, device='cpu').item()\n",
        "cer_value = metric(decode_texts(y_pred, alphabet, 0), [''.join(alphabet[k-1] for k, _ in groupby(e) if k != 0) for e in val_labels.cpu().numpy().astype(int)]).item()\n",
        "print(f'batch_time: {round(time_spent, 6)}, loss: {round(loss, 6)}, metric: {round(cer_value, 6)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB4Jdblf90Pg",
        "outputId": "b1f4f243-606f-4698-b577-acc6a30cd7ec",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_time: 0.008122, loss: 0.611737, metric: 0.047295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* inference w/ PyTorch: {'batch_time': 0.002996, 'loss': 14.042188, 'metric': 0.049073}\n",
        "* inference w/ ORT: batch_time: 0.008122, loss: 0.611737, metric: 0.047295"
      ],
      "metadata": {
        "id": "Ng315Dn2H6hL",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LIe6ku7Dnin5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}