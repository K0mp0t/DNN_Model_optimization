{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["QRR_Kben5_fe"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["https://habr.com/ru/articles/482050/ идею взял из этой статьи. Описана идея слабо, часть пришлось придумывать самому, вроде что-то интересное получилось\n","\n","Список содержимого:\n","1. Функции-хелперы, можно не смотреть\n","2. Загрузка модели\n","3. Функция-обрезчик (портянка кода, но по-другому никак)\n","4. Тесты (валидация-дообучение-валидация) + в самом конце написал выжимку"],"metadata":{"id":"6OsUeVflOHj-"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","\n","drive.mount('/content/drive')"],"metadata":{"id":"cigW6QVE1Ys3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695648570489,"user_tz":-300,"elapsed":15463,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"f43e4fbc-786f-4a4d-cef8-30eddfad2be0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Всякое"],"metadata":{"id":"QRR_Kben5_fe"}},{"cell_type":"code","source":["!pip install -q torchmetrics torchinfo"],"metadata":{"id":"k1hnAdmv1Cqh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695648578583,"user_tz":-300,"elapsed":8096,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"2f2106dd-9abf-4f4d-96c7-9e39fe825438"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/805.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/805.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.8/805.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/805.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from itertools import groupby\n","\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, pool_ksize=(2, 2)):\n","        super(ConvBlock, self).__init__()\n","\n","        self.block = nn.Sequential(nn.Conv2d(in_channels, out_channels, 3, padding='same'),\n","                                   nn.LeakyReLU(0.1),\n","                                   nn.BatchNorm2d(out_channels),\n","                                   nn.MaxPool2d(pool_ksize))\n","\n","    def forward(self, x):\n","        return self.block(x)\n","\n","\n","class CRNN(nn.Module):\n","    def __init__(self, alphabet_len):\n","        super(CRNN, self).__init__()\n","\n","        self.feature_extractor = nn.Sequential(ConvBlock(1, 32),\n","                                               ConvBlock(32, 64, (2, 1)),\n","                                               ConvBlock(64, 64),\n","                                               ConvBlock(64, 128),\n","                                               ConvBlock(128, 256, (2, 1)))\n","        self.lstm1 = nn.LSTM(258, 256, batch_first=True)\n","        self.lstm2 = nn.LSTM(256, 256, batch_first=True)\n","\n","        self.fc = nn.Sequential(nn.Linear(256, alphabet_len+1),\n","                                nn.Softmax(dim=2))\n","\n","    def forward(self, x1, x2):\n","        f1 = self.feature_extractor(x1).squeeze()\n","        f1 = torch.permute(f1, (0, 2, 1))\n","\n","        x = torch.cat([f1, x2], dim=2)\n","\n","        x, _ = self.lstm1(x)\n","        assert x.isnan().sum() == 0, 'nans detected'\n","        x, _ = self.lstm2(x)\n","        assert x.isnan().sum() == 0, 'nans detected'\n","        x = self.fc(x)\n","        assert x.isnan().sum() == 0, 'nans detected'\n","\n","        return x\n","\n","\n","def decode_texts(logits, alphabet):\n","    \"\"\"Decodes CRNN output with given alphabet and whitelist\n","\n","    Args:\n","        logits: np.ndarray, CRNN output\n","        alphabet: str, alphabet CRNN was trained on\n","    Returns:\n","        list of predictions\n","    \"\"\"\n","    best_path_indices = np.argmax(logits, axis=-1)\n","    best_chars_collapsed = [[alphabet[k-1] for k, _ in groupby(e) if k != 0] for e in best_path_indices]\n","    return [''.join(e) for e in best_chars_collapsed]"],"metadata":{"id":"tST1k3mX57Df"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def ctc_loss_log_differentiable_torch(log_logits: torch.FloatTensor, targets: torch.LongTensor,\n","                                      input_lengths: torch.Tensor, target_lengths: torch.Tensor, device,\n","                                      blank_idx=0, dtype_to_use=torch.float32) -> torch.float32:\n","    \"\"\"\n","    log_logits: np.ndarray of shape (B, T, C)\n","    targets: np.ndarray of shape (B, L,)\n","    \"\"\"\n","\n","    B, T = log_logits.shape[0], log_logits.shape[1]\n","    S = 2 * targets.shape[1] + 1\n","\n","    zero = torch.finfo(dtype_to_use).min\n","\n","    # insert blanks between every pair of labels and add them to start and end of the seq\n","    extended_targets = torch.stack([torch.full_like(targets, blank_idx), targets], dim=-1).flatten(start_dim=-2)\n","    extended_targets = torch.cat([extended_targets, torch.full((B, 1), blank_idx, device=device)], dim=-1)\n","    # due to the paper formula for alpha_t(s) we must know where labels repeat and where the blanks are\n","    # in the extended label seq\n","    targets_difference_mask = torch.cat([torch.full((B, 2), False, device=device), extended_targets[:, 2:] != extended_targets[:, :-2]], dim=-1)\n","\n","    # initialize alphas array to keep track of previous alphas\n","    # (also add 2 to the second dim so our s-2 and s-1 vectorized calculations won't get IndexError)\n","    log_alphas = torch.full((B, T, S+2), zero, dtype=dtype_to_use, device=device)\n","\n","    # every accountable prefix starts either with a blank or the first symbol of the target,\n","    # so we initialize alphas in the following way (remember about S+2)\n","    log_alphas[:, 0, 2] = log_logits[:, 0, blank_idx]\n","    log_alphas[:, 0, 3] = log_logits[torch.arange(B), 0, targets[:, 0]]\n","\n","    for t in range(1, T):\n","        # remember we're in log space so log(a*b) = log(a) + log(b)\n","        # here formula must be mathematically reworked.\n","\n","        log_alphas[:, t, 2:] = (torch.gather(log_logits[:, t], -1, extended_targets) +\n","                                torch.logsumexp(torch.stack([log_alphas[:, t-1, 2:], log_alphas[:, t-1, 1: -1],\n","                                                             torch.where(targets_difference_mask,\n","                                                                         log_alphas[:, t-1, :-2], zero)]), dim=0))\n","\n","    temp = torch.gather(log_alphas[np.arange(B), input_lengths-1], -1,\n","                        torch.stack([2 + target_lengths * 2 - 1, 2 + target_lengths * 2], dim=-1))\n","\n","    return -torch.mean(torch.logsumexp(temp, dim=-1))"],"metadata":{"id":"21TiL7XdLVnP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, epochs, train_loader, lr, device='cpu'):\n","  model.to(device)\n","  model.train()\n","\n","  optimizer = torch.optim.NAdam(model.parameters(), lr=lr)\n","  metric = CharErrorRate()\n","\n","  criterion = ctc_loss_log_differentiable_torch\n","\n","  for epoch in range(epochs):\n","    train_loss = 0\n","    val_loss = 0\n","\n","    train_cer = 0\n","    val_cer = 0\n","\n","    for i, ((x1, x2), y) in enumerate(train_loader):\n","      x1 = x1.to(device)\n","      x2 = x2.to(device)\n","      y = y.to(device)\n","\n","      optimizer.zero_grad()\n","      y_pred = model(x1, x2)\n","\n","      input_lengths = torch.full((y_pred.shape[0],), y_pred.shape[1]).to(device)\n","      target_lengths = torch.sum(y != 0, axis=1)\n","\n","      loss = criterion(torch.log(y_pred), y, input_lengths, target_lengths, device=device)\n","      loss.backward()\n","\n","      optimizer.step()\n","\n","      train_loss += loss.item()\n","      train_cer += metric(decode_texts(y_pred.detach().cpu().numpy(), alphabet),\n","                          [''.join(alphabet[k-1] for k, _ in groupby(e) if k != 0) for e in y.cpu().numpy().astype(int)]).item()\n","\n","      print(f'\\rEpoch {epoch}, {i+1}/{len(train_loader)}, loss: {round(train_loss/(i+1), 6)}, cer: {round(train_cer/(i+1), 6)}', end='')\n","    print()\n","\n","  return model"],"metadata":{"id":"wTT6SvNb_cFy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchmetrics.text import CharErrorRate\n","from itertools import groupby\n","from tqdm import tqdm\n","import time\n","\n","def validate_model(model, dataloader, device='cpu'):\n","  model.eval()\n","\n","  criterion = ctc_loss_log_differentiable_torch\n","  metric = CharErrorRate()\n","  loss = 0\n","  cer_value = 0\n","  cumtime = 0\n","\n","  with torch.no_grad():\n","    for i, ((x1, x2), y) in tqdm(enumerate(dataloader)):\n","      x1 = x1.to(device)\n","      x2 = x2.to(device)\n","      y = y.to(device)\n","\n","      start = time.time()\n","      y_pred = model(x1, x2)\n","      cumtime += time.time() - start\n","\n","      input_lengths = torch.full((y_pred.shape[0],), y_pred.shape[1]).to(device)\n","      target_lengths = torch.sum(y != 0, axis=1)\n","      loss += criterion(torch.log(y_pred), y, input_lengths, target_lengths, device=device).item()\n","      cer_value += metric(decode_texts(y_pred.detach().cpu().numpy(), alphabet),\n","                        [''.join(alphabet[k-1] for k, _ in groupby(e) if k != 0) for e in y.cpu().numpy().astype(int)]).item()\n","\n","  print()\n","\n","  return cumtime / len(dataloader), loss / len(dataloader), cer_value / len(dataloader)"],"metadata":{"id":"pgSSZwAe_jNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","\n","class OCRDataset(Dataset):\n","    def __init__(self, images, abits, labels):\n","        super(OCRDataset, self).__init__()\n","\n","        self.images = images\n","        self.abits = abits\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return self.labels.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return (torch.FloatTensor(self.images[idx]).unsqueeze(0), torch.FloatTensor(self.abits[idx])), torch.IntTensor(self.labels[idx])"],"metadata":{"id":"gWmOQXHj_9WR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import h5py\n","import pandas as pd\n","import numpy as np\n","\n","with h5py.File('/content/drive/MyDrive/CRNN for long fields/common_fields_images.h5') as f:\n","    images = f['images'][:]\n","    additional_bits = f['additional_bit'][:]\n","\n","with open('/content/drive/MyDrive/CRNN for long fields/common_fields_labels.txt', encoding='cp1251') as f:\n","    markup = [e.strip() for e in f.readlines()]\n","\n","\n","def encode_texts(texts):\n","    def _label_to_num(label, alphabet):\n","        label_num = []\n","        for ch in label:\n","            label_num.append(alphabet.find(ch) + 1)\n","        return np.array(label_num)\n","\n","    # alphabet = ''.join(sorted(pd.Series(texts).apply(list).apply(pd.Series).stack().unique()))\n","    alphabet = ''.join(sorted(set(''.join(texts))))\n","\n","    nums = np.zeros([len(texts), max([len(text) for text in texts])], dtype='int64')\n","    for i, text in enumerate(texts):\n","        nums[i][:len(text)] = _label_to_num(text, alphabet)\n","\n","    return nums, alphabet\n","\n","labels_encoded, alphabet = encode_texts(markup)\n","images = images.astype('float64') / 255\n","\n","additional_bits_expanded = np.zeros((len(images), 50, 2))\n","additional_bits_expanded[:, :, additional_bits] = 1\n","\n","np.random.seed(42)\n","\n","train_indices = np.random.choice(np.arange(images.shape[0]), int(images.shape[0]*0.8), replace=False)\n","val_indices = [e for e in np.arange(images.shape[0]) if e not in train_indices]\n","\n","assert len(set(train_indices) & set(val_indices)) == 0\n","assert len(set(train_indices) | set(val_indices)) == images.shape[0]\n","\n","train_imgs = images[train_indices]\n","val_imgs = images[val_indices]\n","\n","train_abits = additional_bits_expanded[train_indices]\n","val_abits = additional_bits_expanded[val_indices]\n","\n","train_labels = labels_encoded[train_indices]\n","val_labels = labels_encoded[val_indices]\n","\n","train_dataset = OCRDataset(train_imgs, train_abits, train_labels)\n","val_dataset = OCRDataset(val_imgs, val_abits, val_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=128)\n","val_loader = DataLoader(val_dataset, batch_size=128)"],"metadata":{"id":"SMeMZc2cADPF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Загрузка и обрезание модели"],"metadata":{"id":"nxSVQJEi6Y0m"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7JWAmGEQz9LF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695648618884,"user_tz":-300,"elapsed":13755,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"081bda37-33ce-456a-ddfe-87c322da4bdd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","CRNN                                     [32, 50, 46]              --\n","├─Sequential: 1-1                        [32, 256, 1, 50]          --\n","│    └─ConvBlock: 2-1                    [32, 32, 16, 200]         --\n","│    │    └─Sequential: 3-1              [32, 32, 16, 200]         384\n","│    └─ConvBlock: 2-2                    [32, 64, 8, 200]          --\n","│    │    └─Sequential: 3-2              [32, 64, 8, 200]          18,624\n","│    └─ConvBlock: 2-3                    [32, 64, 4, 100]          --\n","│    │    └─Sequential: 3-3              [32, 64, 4, 100]          37,056\n","│    └─ConvBlock: 2-4                    [32, 128, 2, 50]          --\n","│    │    └─Sequential: 3-4              [32, 128, 2, 50]          74,112\n","│    └─ConvBlock: 2-5                    [32, 256, 1, 50]          --\n","│    │    └─Sequential: 3-5              [32, 256, 1, 50]          295,680\n","├─LSTM: 1-2                              [32, 50, 256]             528,384\n","├─LSTM: 1-3                              [32, 50, 256]             526,336\n","├─Sequential: 1-4                        [32, 50, 46]              --\n","│    └─Linear: 2-6                       [32, 50, 46]              11,822\n","│    └─Softmax: 2-7                      [32, 50, 46]              --\n","==========================================================================================\n","Total params: 1,492,398\n","Trainable params: 1,492,398\n","Non-trainable params: 0\n","Total mult-adds (G): 7.49\n","==========================================================================================\n","Input size (MB): 1.65\n","Forward/backward pass size (MB): 413.47\n","Params size (MB): 5.97\n","Estimated Total Size (MB): 421.09\n","=========================================================================================="]},"metadata":{},"execution_count":9}],"source":["import torch\n","from torchinfo import summary\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model_ = CRNN(len(alphabet))\n","model_.load_state_dict(torch.load('/content/drive/MyDrive/Методы компрессии/crnn_common_fields_.pt', map_location=torch.device(device)))\n","summary(model_, input_size=[(32, 1, 32, 400), (32, 50, 2)], device=device)"]},{"cell_type":"code","source":["print(dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model_, val_loader, device=device)])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETKsYXtIWqQw","executionInfo":{"status":"ok","timestamp":1695648620655,"user_tz":-300,"elapsed":1785,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"a59ca869-f0b1-47eb-b6b3-6d576319c4e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["26it [00:01, 14.22it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","{'batch_time': 0.032099, 'loss': 0.623181, 'metric': 0.049073}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["Пока что пришлось отключить прунинг рекуррентных и полносвязных слоев потому что там где-то есть проблемка (скорее всего в прунинге рекуррентных слоев)"],"metadata":{"id":"mbUERfndXY7n"}},{"cell_type":"code","source":["from ast import Module\n","from copy import deepcopy\n","\n","model = deepcopy(model_)\n","\n","layers_to_prune = list()\n","\n","def get_layers(module):\n","    children = list(module.children())\n","    return [module] if len(children) == 0 else [ci for c in children for ci in get_layers(c)]\n","\n","\n","model.to('cpu')\n","\n","layers = get_layers(model)\n","layers_to_prune = list(filter(lambda x: isinstance(x, (nn.Conv2d, nn.BatchNorm2d, nn.LSTM, nn.Linear)), layers))[:-1]\n","# layers_to_prune = list(filter(lambda x: isinstance(x, (nn.Conv2d, nn.BatchNorm2d)), layers))\n","layers_to_prune"],"metadata":{"id":"c3OO2C3_3HcZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695648702545,"user_tz":-300,"elapsed":299,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"89c12ba4-75fc-4ca9-d953-9257fd713088"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same),\n"," BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same),\n"," BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same),\n"," BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same),\n"," BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same),\n"," BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," LSTM(258, 256, batch_first=True)]"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fraction = 0.1\n","\n","sorted_indices = None\n","prev_layer_output_size = 0\n","prunable_counter = 0\n","\n","for i, layer in enumerate(layers_to_prune):\n","  # first process indices from previous layer\n","  if sorted_indices is not None:\n","    if isinstance(layer, nn.Conv2d):\n","      layer.in_channels = len(sorted_indices)\n","      layer.weight = torch.nn.Parameter(layer.weight[:, sorted_indices])\n","    elif isinstance(layer, nn.BatchNorm2d):\n","      layer.num_features = len(sorted_indices)\n","\n","      layer.weight = torch.nn.Parameter(layer.weight[sorted_indices])\n","      layer.bias = torch.nn.Parameter(layer.bias[sorted_indices])\n","      layer.running_mean = layer.running_mean[sorted_indices]\n","      layer.running_var = layer.running_var[sorted_indices]\n","    elif isinstance(layer, nn.LSTM):\n","      # its here due to conv extracted features concatenation with second input\n","      sorted_indices = list(set(np.arange(layer.input_size)) - (set(np.arange(prev_layer_output_size)) - set(sorted_indices.numpy())))\n","\n","      for attr in dir(layer):\n","        if attr.startswith('weight_ih'):\n","          layer.input_size = len(sorted_indices)\n","          setattr(layer, attr, torch.nn.Parameter(getattr(layer, attr)[:, sorted_indices]))\n","\n","    elif isinstance(layer, nn.Linear):\n","      layer.in_features = len(sorted_indices)\n","      layer.weight = torch.nn.Parameter(layer.weight[:, sorted_indices])\n","\n","  if len(layers_to_prune) - i <= 1:\n","    break\n","\n","  # third prune\n","  if isinstance(layer, nn.Conv2d):\n","    l1_kernelwise = torch.sum(torch.abs(layer.weight), dim=(1, 2, 3)).detach()\n","    sorted_indices = torch.argsort(l1_kernelwise)[int(fraction*layer.out_channels):]\n","    sorted_indices = torch.sort(sorted_indices).values\n","\n","    prev_layer_output_size = layer.out_channels\n","    layer.out_channels = len(sorted_indices)\n","    layer.weight = torch.nn.Parameter(layer.weight[sorted_indices])\n","    layer.bias = torch.nn.Parameter(layer.bias[sorted_indices])\n","\n","  elif isinstance(layer, nn.LSTM):\n","    prev_layer_output_size = layer.hidden_size\n","\n","    for attr in dir(layer):\n","      if attr.startswith('weight_ih'):\n","        weight = getattr(layer, attr).view(layer.hidden_size, 4, -1)\n","        l1 = torch.sum(torch.abs(weight), dim=(1, 2))\n","        sorted_indices = torch.argsort(l1)[int(fraction*layer.hidden_size):]\n","        sorted_indices = torch.sort(sorted_indices).values\n","\n","        bias_name = attr.replace('weight', 'bias')\n","        setattr(layer, attr, torch.nn.Parameter(weight[sorted_indices].view(-1, weight.shape[-1])))\n","        setattr(layer, bias_name, torch.nn.Parameter(getattr(layer, bias_name)[sorted_indices]))\n","\n","    for attr in dir(layer):\n","      if attr.startswith('weight_hh'):\n","        weight = getattr(layer, attr)[:, sorted_indices].view(layer.hidden_size, 4, -1)\n","        l1 = torch.sum(torch.abs(weight), dim=(1, 2))\n","        sorted_indices = torch.argsort(l1)[int(fraction*layer.hidden_size):]\n","        sorted_indices = torch.sort(sorted_indices).values\n","\n","        bias_name = attr.replace('weight', 'bias')\n","        setattr(layer, attr, torch.nn.Parameter(weight[sorted_indices].view(-1, weight.shape[-1])))\n","        setattr(layer, bias_name, torch.nn.Parameter(getattr(layer, bias_name)[sorted_indices]))\n","\n","    layer.hidden_size = len(sorted_indices)\n","\n","  elif isinstance(layer, nn.Linear):\n","    l1 = torch.sum(torch.abs(layer.weight), dim=1)\n","    sorted_indices = torch.argsort(l1)[int(fraction*layer.in_features):]\n","    sorted_indices = torch.sort(sorted_indices).values\n","\n","    layer.weight = torch.nn.Parameter(layer.weight[sorted_indices])\n","\n","    layer.out_features = len(sorted_indices)"],"metadata":{"id":"KA4jByPd7QGn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Тесты"],"metadata":{"id":"7T7B-lH8OTXi"}},{"cell_type":"markdown","source":["Внутрь модельки засунул assert, который проверяет, что в выходе нет nan'ов. Почему-то они там возникают, если прунить каналы в рекуррентной части сети, это я позже попробую исправить"],"metadata":{"id":"-odNLNcyVh8K"}},{"cell_type":"code","source":["summary(model, input_size=[(32, 1, 32, 400), (32, 50, 2)], device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-1AEBhyUkN7","executionInfo":{"status":"ok","timestamp":1695648707853,"user_tz":-300,"elapsed":295,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"925df10d-e862-4dc6-9b1b-f039c60c5149"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","CRNN                                     [32, 50, 46]              --\n","├─Sequential: 1-1                        [32, 231, 1, 50]          --\n","│    └─ConvBlock: 2-1                    [32, 29, 16, 200]         --\n","│    │    └─Sequential: 3-1              [32, 29, 16, 200]         348\n","│    └─ConvBlock: 2-2                    [32, 58, 8, 200]          --\n","│    │    └─Sequential: 3-2              [32, 58, 8, 200]          15,312\n","│    └─ConvBlock: 2-3                    [32, 58, 4, 100]          --\n","│    │    └─Sequential: 3-3              [32, 58, 4, 100]          30,450\n","│    └─ConvBlock: 2-4                    [32, 116, 2, 50]          --\n","│    │    └─Sequential: 3-4              [32, 116, 2, 50]          60,900\n","│    └─ConvBlock: 2-5                    [32, 231, 1, 50]          --\n","│    │    └─Sequential: 3-5              [32, 231, 1, 50]          241,857\n","├─LSTM: 1-2                              [32, 50, 256]             502,784\n","├─LSTM: 1-3                              [32, 50, 256]             526,336\n","├─Sequential: 1-4                        [32, 50, 46]              --\n","│    └─Linear: 2-6                       [32, 50, 46]              11,822\n","│    └─Softmax: 2-7                      [32, 50, 46]              --\n","==========================================================================================\n","Total params: 1,389,809\n","Trainable params: 1,389,809\n","Non-trainable params: 0\n","Total mult-adds (G): 6.42\n","==========================================================================================\n","Input size (MB): 1.65\n","Forward/backward pass size (MB): 375.32\n","Params size (MB): 5.56\n","Estimated Total Size (MB): 382.53\n","=========================================================================================="]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["print(dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, device=device)])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OT2gkP3qK1BT","executionInfo":{"status":"ok","timestamp":1695648710714,"user_tz":-300,"elapsed":1609,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"f42fe536-c1b0-44fd-81fc-d70802a7ac91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["26it [00:01, 15.09it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","{'batch_time': 0.029588, 'loss': 0.904908, 'metric': 0.055323}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["torch.autograd.set_detect_anomaly(True)\n","\n","model = train_model(model, 2, train_loader, lr=1e-4, device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DUm1lWXt-kW4","executionInfo":{"status":"ok","timestamp":1695648845090,"user_tz":-300,"elapsed":132084,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"4c994fc7-062d-44de-b456-91a0311d67b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0, 103/103, loss: 0.214567, cer: 0.038388\n","Epoch 1, 103/103, loss: 0.152685, cer: 0.037062\n"]}]},{"cell_type":"code","source":["print(dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, device=device)])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inpVXhBNMYnv","executionInfo":{"status":"ok","timestamp":1695649168941,"user_tz":-300,"elapsed":1833,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"e07327ec-5dba-451a-8611-0188707c8e3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["26it [00:01, 15.24it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","{'batch_time': 0.029938, 'loss': 0.549252, 'metric': 0.047336}\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["* Было: {'batch_time': 0.0312, 'loss': 0.623181, 'metric': 0.049073}\n","* После прунинга (без дообучения) стало: {'batch_time': 0.029588, 'loss': 0.904908, 'metric': 0.055323}\n","* После прунинга (с дообучением) стало: {'batch_time': 0.025779, 'loss': 0.551292, 'metric': 0.047284}"],"metadata":{"id":"YR3RuDJ_X_o-"}},{"cell_type":"markdown","source":["https://stackoverflow.com/questions/52945427/pytorch-manually-setting-weight-parameters-with-numpy-array-for-gru-lstm"],"metadata":{"id":"wxdOW91tOB-M"}},{"cell_type":"code","source":[],"metadata":{"id":"iJhkw28iL1Iz"},"execution_count":null,"outputs":[]}]}