{"cells":[{"cell_type":"markdown","metadata":{"id":"WxnCqpsYvGFf"},"source":["Взяли модельку и набор данных с моей работки. Моделька делает OCR"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOl5YbUkvxAQ","executionInfo":{"status":"ok","timestamp":1695402393440,"user_tz":-300,"elapsed":19323,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"9b654e09-a75e-4922-ca15-93c584e506aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"kYicwQGSvGFj"},"source":["# Берем и смотрим данные"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWe9l99SNQmg"},"outputs":[],"source":["import h5py\n","import pandas as pd\n","\n","with h5py.File('/content/drive/MyDrive/Методы компрессии/common_fields_images.h5') as f:\n","    images = f['images'][:]\n","    additional_bits = f['additional_bit'][:]\n","\n","with open('/content/drive/MyDrive/Методы компрессии/common_fields_labels.txt', encoding='cp1251') as f:\n","    markup = [e.strip() for e in f.readlines()]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1695402400242,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"},"user_tz":-300},"id":"TntRnvxIuIbq","outputId":"4328c25d-b4ba-460f-eb41-cfa06cf7b3e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((16462, 32, 400), (16462,), 16462)"]},"metadata":{},"execution_count":3}],"source":["images.shape, additional_bits.shape, len(markup)"]},{"cell_type":"markdown","metadata":{"id":"um-rMfoCvGFm"},"source":["# Кодируем данные и подгоняем размерности"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"shmKTjfOOQr2"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def encode_texts(texts):\n","    def _label_to_num(label, alphabet):\n","        label_num = []\n","        for ch in label:\n","            label_num.append(alphabet.find(ch))\n","        return np.array(label_num)\n","\n","    alphabet = ''.join(sorted(pd.Series(texts).apply(list).apply(pd.Series).stack().unique()))\n","\n","    nums = np.ones([len(texts), max([len(text) for text in texts])], dtype='int64') * len(alphabet)\n","    for i, text in enumerate(texts):\n","        nums[i][:len(text)] = _label_to_num(text, alphabet)\n","\n","    return nums, alphabet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fa7dQz99PXDO"},"outputs":[],"source":["labels_encoded, alphabet = encode_texts(markup)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WLH3hXWVReOM"},"outputs":[],"source":["images = images.astype('float64') / 255\n","\n","additional_bits_expanded = np.zeros((len(images), 50, 2))\n","additional_bits_expanded[:, :, additional_bits] = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1695402419745,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"},"user_tz":-300},"id":"FAB0wetUMBlf","outputId":"36af027b-805a-40fe-c122-16ec57f7c117"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(16462, 50, 2)"]},"metadata":{},"execution_count":7}],"source":["additional_bits_expanded.shape"]},{"cell_type":"markdown","metadata":{"id":"THr_6N9IvGFp"},"source":["# ФП, метрика и модель"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cX6WQ7cRrYt"},"outputs":[],"source":["import tensorflow as tf\n","from keras import backend as K\n","\n","\n","class CER(tf.keras.metrics.Metric):\n","    \"\"\"\n","    A custom Keras metric to compute the Character Error Rate\n","    \"\"\"\n","    def __init__(self, name='CER', decode_greedy=True, **kwargs):\n","        super(CER, self).__init__(name=name, **kwargs)\n","        self.decode_greedy = decode_greedy\n","        self.cer_accumulator = self.add_weight(name=\"total_cer\", initializer=\"zeros\")\n","        self.counter = self.add_weight(name=\"cer_count\", initializer=\"zeros\")\n","\n","    def update_state(self, y_true, y_pred, sample_weight=None):\n","        input_shape = K.shape(y_pred)\n","        input_length = tf.ones(shape=input_shape[0]) * K.cast(input_shape[1], 'float32')\n","\n","        decode, log = K.ctc_decode(y_pred, input_length, greedy=True)\n","\n","        decode = K.ctc_label_dense_to_sparse(decode[0], K.cast(input_length, 'int32'))\n","        y_true_sparse = K.ctc_label_dense_to_sparse(y_true, K.cast(input_length, 'int32'))\n","        y_true_sparse = tf.sparse.retain(y_true_sparse, tf.not_equal(y_true_sparse.values, tf.math.reduce_max(y_true_sparse.values)))\n","\n","        decode = tf.sparse.retain(decode, tf.not_equal(decode.values, -1))\n","        distance = tf.edit_distance(decode, y_true_sparse, normalize=True)\n","\n","        self.cer_accumulator.assign_add(tf.reduce_sum(distance))\n","        self.counter.assign_add(K.cast(len(y_true), 'float32'))\n","\n","    def result(self):\n","        return tf.math.divide_no_nan(self.cer_accumulator, self.counter)\n","\n","    def reset_state(self):\n","        self.cer_accumulator.assign(0.0)\n","        self.counter.assign(0.0)\n","\n","\n","def CTCLoss(y_true, y_pred):\n","    \"\"\"\n","    Compute the training-time loss value\n","    \"\"\"\n","    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n","    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n","    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n","\n","    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n","\n","    loss = K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BosfOmNvGFq"},"outputs":[],"source":["model = tf.keras.models.load_model('/content/drive/MyDrive/Методы компрессии/crnn_common_fields.h5', custom_objects={'CTCLoss': CTCLoss, 'CER': CER})"]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0lmMOtKRvh0j","executionInfo":{"status":"ok","timestamp":1695402426986,"user_tz":-300,"elapsed":780,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"}},"outputId":"e786a0b4-ba0d-46c2-bd7d-84e35fbfe5bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, 32, 400, 1)]         0         []                            \n","                                                                                                  \n"," conv2d (Conv2D)             (None, 32, 400, 32)          320       ['input_2[0][0]']             \n","                                                                                                  \n"," batch_normalization (Batch  (None, 32, 400, 32)          128       ['conv2d[0][0]']              \n"," Normalization)                                                                                   \n","                                                                                                  \n"," leaky_re_lu (LeakyReLU)     (None, 32, 400, 32)          0         ['batch_normalization[0][0]'] \n","                                                                                                  \n"," dropout (Dropout)           (None, 32, 400, 32)          0         ['leaky_re_lu[0][0]']         \n","                                                                                                  \n"," max_pooling2d (MaxPooling2  (None, 16, 200, 32)          0         ['dropout[0][0]']             \n"," D)                                                                                               \n","                                                                                                  \n"," conv2d_1 (Conv2D)           (None, 16, 200, 64)          18496     ['max_pooling2d[0][0]']       \n","                                                                                                  \n"," batch_normalization_1 (Bat  (None, 16, 200, 64)          256       ['conv2d_1[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_1 (LeakyReLU)   (None, 16, 200, 64)          0         ['batch_normalization_1[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_1 (Dropout)         (None, 16, 200, 64)          0         ['leaky_re_lu_1[0][0]']       \n","                                                                                                  \n"," max_pooling2d_1 (MaxPoolin  (None, 8, 200, 64)           0         ['dropout_1[0][0]']           \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_2 (Conv2D)           (None, 8, 200, 64)           36928     ['max_pooling2d_1[0][0]']     \n","                                                                                                  \n"," batch_normalization_2 (Bat  (None, 8, 200, 64)           256       ['conv2d_2[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_2 (LeakyReLU)   (None, 8, 200, 64)           0         ['batch_normalization_2[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_2 (Dropout)         (None, 8, 200, 64)           0         ['leaky_re_lu_2[0][0]']       \n","                                                                                                  \n"," max_pooling2d_2 (MaxPoolin  (None, 4, 100, 64)           0         ['dropout_2[0][0]']           \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_3 (Conv2D)           (None, 4, 100, 128)          73856     ['max_pooling2d_2[0][0]']     \n","                                                                                                  \n"," batch_normalization_3 (Bat  (None, 4, 100, 128)          512       ['conv2d_3[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_3 (LeakyReLU)   (None, 4, 100, 128)          0         ['batch_normalization_3[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_3 (Dropout)         (None, 4, 100, 128)          0         ['leaky_re_lu_3[0][0]']       \n","                                                                                                  \n"," max_pooling2d_3 (MaxPoolin  (None, 2, 50, 128)           0         ['dropout_3[0][0]']           \n"," g2D)                                                                                             \n","                                                                                                  \n"," conv2d_4 (Conv2D)           (None, 2, 50, 256)           295168    ['max_pooling2d_3[0][0]']     \n","                                                                                                  \n"," batch_normalization_4 (Bat  (None, 2, 50, 256)           1024      ['conv2d_4[0][0]']            \n"," chNormalization)                                                                                 \n","                                                                                                  \n"," leaky_re_lu_4 (LeakyReLU)   (None, 2, 50, 256)           0         ['batch_normalization_4[0][0]'\n","                                                                    ]                             \n","                                                                                                  \n"," dropout_4 (Dropout)         (None, 2, 50, 256)           0         ['leaky_re_lu_4[0][0]']       \n","                                                                                                  \n"," max_pooling2d_4 (MaxPoolin  (None, 1, 50, 256)           0         ['dropout_4[0][0]']           \n"," g2D)                                                                                             \n","                                                                                                  \n"," input_1 (InputLayer)        [(None, 50, 2)]              0         []                            \n","                                                                                                  \n"," reshape (Reshape)           (None, 50, 256)              0         ['max_pooling2d_4[0][0]']     \n","                                                                                                  \n"," concatenate (Concatenate)   (None, 50, 258)              0         ['input_1[0][0]',             \n","                                                                     'reshape[0][0]']             \n","                                                                                                  \n"," lstm (LSTM)                 (None, 50, 256)              527360    ['concatenate[0][0]']         \n","                                                                                                  \n"," lstm_1 (LSTM)               (None, 50, 256)              525312    ['lstm[0][0]']                \n","                                                                                                  \n"," dense (Dense)               (None, 50, 46)               11822     ['lstm_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 1491438 (5.69 MB)\n","Trainable params: 1490350 (5.69 MB)\n","Non-trainable params: 1088 (4.25 KB)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"ysz-TGOavGFq"},"source":["Архитектура модели, если интересно, ниже. Чтобы увеличить можно поменять стиль картинки"]},{"cell_type":"markdown","metadata":{"id":"mnq3UUfwvGFq"},"source":["<img src=\"crnn_common_fields.png\" alt=\"Alternative text\" style=\"height:1000px\"/>"]},{"cell_type":"markdown","metadata":{"id":"mrt9pLjsvGFq"},"source":["# Непосредственно замер\n","\n","Не уверен, как правильно замерять скорость inference в TF, оставлю так пока"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339989,"status":"ok","timestamp":1695404511179,"user":{"displayName":"Petr Ivanov","userId":"15588216699611977235"},"user_tz":-300},"id":"tFmt1HElizm_","outputId":"223d3817-2257-45b7-e0f6-9848de2220d8"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [05:36<00:00, 33.61s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Time spent: 0.02626\n","loss: 0.007197999861091375, Character Error Rate: 0.0\n"]}],"source":["import time\n","from tqdm import trange\n","\n","NRUNS = 10\n","DLEN = 1280\n","\n","start = time.time()\n","\n","for i in trange(NRUNS):\n","  y_pred = model.predict([additional_bits_expanded[:DLEN], images[:DLEN]], batch_size=64, verbose=0)\n","\n","print(f'Time spent: {(round((time.time()-start) / NRUNS / DLEN, 6))}')\n","\n","loss = CTCLoss(labels_encoded[:DLEN], y_pred)\n","cer = CER()\n","cer.update_state(labels_encoded[:DLEN], y_pred)\n","\n","print(f'loss: {round(tf.reduce_mean(loss).numpy(), 6)}, Character Error Rate: {round(cer.result().numpy(), 6)}')"]},{"cell_type":"markdown","source":["Правильно использовать для валидации весь датасет т.к. на тренировочной части и правда может быть нулевая ошибка"],"metadata":{"id":"qMzASvgoTir9"}},{"cell_type":"code","source":[],"metadata":{"id":"lAzi2IkC4rx1"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["kYicwQGSvGFj","um-rMfoCvGFm"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}