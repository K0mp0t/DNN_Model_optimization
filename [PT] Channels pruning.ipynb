{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Prerequisites (results below)"
   ],
   "metadata": {
    "id": "oT7aJrb1q4S6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import sys\n",
    "\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "sys.path.append('/content/drive/MyDrive/dnn_model_optimization')"
   ],
   "metadata": {
    "id": "cigW6QVE1Ys3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684411492,
     "user_tz": -300,
     "elapsed": 1826,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "951002df-c87f-47b9-db06-fc5d0a8db465",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q torchmetrics torchinfo"
   ],
   "metadata": {
    "id": "k1hnAdmv1Cqh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684416471,
     "user_tz": -300,
     "elapsed": 4980,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils.torch_helpers import train_model, validate_model, warmup_torch_model\n",
    "from utils.torch_model import CRNN\n",
    "from utils.torch_pruning import prune_torch_model, get_layers_to_prune\n",
    "from utils.data import decode_texts, load_data, OCRDataset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchinfo import summary\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "((train_imgs, train_abits), train_labels), ((val_imgs, val_abits), val_labels), alphabet = load_data('/content/drive/MyDrive/dnn_model_optimization/data', split=True)\n",
    "\n",
    "train_dataset = OCRDataset(train_imgs, train_abits, train_labels)\n",
    "val_dataset = OCRDataset(val_imgs, val_abits, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)"
   ],
   "metadata": {
    "id": "SMeMZc2cADPF",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684434987,
     "user_tz": -300,
     "elapsed": 18518,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load model and make a copy of it so we dont have to reload it from disk every time smth goes south"
   ],
   "metadata": {
    "id": "LKz-oKalrzwr",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7JWAmGEQz9LF",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684439687,
     "user_tz": -300,
     "elapsed": 4714,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "f91ef02e-4ab5-4e4e-b51d-85b3f12ba026",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CRNN                                     [32, 50, 46]              --\n",
       "├─Sequential: 1-1                        [32, 256, 1, 50]          425,856\n",
       "├─LSTM: 1-2                              [32, 50, 256]             528,384\n",
       "├─LSTM: 1-3                              [32, 50, 256]             526,336\n",
       "├─Sequential: 1-4                        [32, 50, 46]              11,822\n",
       "==========================================================================================\n",
       "Total params: 1,492,398\n",
       "Trainable params: 1,492,398\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 7.49\n",
       "==========================================================================================\n",
       "Input size (MB): 1.65\n",
       "Forward/backward pass size (MB): 413.47\n",
       "Params size (MB): 5.97\n",
       "Estimated Total Size (MB): 421.09\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = CRNN(len(alphabet))\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/dnn_model_optimization/weights/crnn_common_fields_.pt', map_location=torch.device(device)))\n",
    "summary(model, input_size=[(32, 1, 32, 400), (32, 50, 2)], device=device, depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('Original model before warmup: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, alphabet, device=device)])))\n",
    "warmup_torch_model(model, [(32, 1, 32, 400), (32, 50, 2)], device)\n",
    "print('Original model after warmup: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, alphabet, device=device)])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KAZP2TCMdOab",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684473820,
     "user_tz": -300,
     "elapsed": 34135,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "6862fb58-04ad-44f5-e025-e4b09ce36482",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original model before warmup:  {'batch_time': 0.004436, 'loss': 14.042188, 'metric': 0.049073}\n",
      "Original model after warmup:  {'batch_time': 0.004552, 'loss': 14.042188, 'metric': 0.049073}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get ALL layers we want to prune (and others that will be affected).\n",
    "\n",
    "Here I try to prune every layer, though, as the experimets had shown, it's better to leave RNN layers out of pruning. Partial pruning below\n",
    "\n",
    "Also, it must be considered that some optionally trainable layers such as BatchNorm should be pruned to maintain shapes"
   ],
   "metadata": {
    "id": "mbUERfndXY7n",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_to_prune = deepcopy(model)\n",
    "\n",
    "model_to_prune.to('cpu')\n",
    "\n",
    "layers = get_layers_to_prune(model_to_prune)\n",
    "layers_to_prune = list(filter(lambda x: isinstance(x, (nn.Conv2d, nn.BatchNorm2d, nn.LSTM, nn.Linear)), layers))\n",
    "# layers_to_prune = list(filter(lambda x: isinstance(x, (nn.Conv2d, nn.BatchNorm2d)), layers))\n",
    "layers_to_prune"
   ],
   "metadata": {
    "id": "c3OO2C3_3HcZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684473820,
     "user_tz": -300,
     "elapsed": 6,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "96ab09e5-aa1a-4527-9afa-ff476facfa26",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " LSTM(258, 256, batch_first=True),\n",
       " LSTM(256, 256, batch_first=True),\n",
       " Linear(in_features=256, out_features=46, bias=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pruning function moved to utils/torch_pruning.py. Its pure torch, so make sure to check it if you're interested"
   ],
   "metadata": {
    "id": "98yY_qykrBtE",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "prune_torch_model(layers_to_prune)"
   ],
   "metadata": {
    "id": "KA4jByPd7QGn",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684473821,
     "user_tz": -300,
     "elapsed": 5,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "summary(model_to_prune, input_size=[(32, 1, 32, 400), (32, 50, 2)], device=device, depth=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-1AEBhyUkN7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684473821,
     "user_tz": -300,
     "elapsed": 4,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "c81788f4-6436-4faf-dbdc-9a25fc6abe38",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CRNN                                     [32, 50, 46]              --\n",
       "├─Sequential: 1-1                        [32, 231, 1, 50]          348,867\n",
       "├─LSTM: 1-2                              [32, 50, 231]             430,584\n",
       "├─LSTM: 1-3                              [32, 50, 231]             428,736\n",
       "├─Sequential: 1-4                        [32, 50, 46]              10,672\n",
       "==========================================================================================\n",
       "Total params: 1,218,859\n",
       "Trainable params: 1,218,859\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.15\n",
       "==========================================================================================\n",
       "Input size (MB): 1.65\n",
       "Forward/backward pass size (MB): 374.68\n",
       "Params size (MB): 4.88\n",
       "Estimated Total Size (MB): 381.21\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see model lost about 300K parameters during pruning. Lets validate it, tune it a little bit and validate again"
   ],
   "metadata": {
    "id": "8VTp8rbmrLv3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "warmup_torch_model(model_to_prune, [(32, 1, 32, 400), (32, 50, 2)], device)\n",
    "print('Full prunned model w/o tuning: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model_to_prune, val_loader, alphabet, device=device)])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OT2gkP3qK1BT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684488001,
     "user_tz": -300,
     "elapsed": 14183,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "2f854aa7-d74d-459a-afa1-6f935d210c28",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Full prunned model w/o tuning:  {'batch_time': 0.003171, 'loss': 16.876544, 'metric': 1.40559}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "best_state, _ = train_model(model_to_prune,  alphabet, 2, train_loader, val_loader, lr=5e-4, device=device)\n",
    "model_to_prune.load_state_dict(best_state)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUm1lWXt-kW4",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684546250,
     "user_tz": -300,
     "elapsed": 58262,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "9b2110f5-495f-430e-edc1-432d1434d495",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0, 103/103, loss: 22.635205, cer: 0.554532, val_loss: 8.270752, val_cer: 0.231835\n",
      "Epoch 1, 103/103, loss: 1.505179, cer: 0.049289, val_loss: 3.5633, val_cer: 0.121446\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print('Full prunned model w/ tuning: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model_to_prune, val_loader, alphabet, device=device)])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inpVXhBNMYnv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684560245,
     "user_tz": -300,
     "elapsed": 13998,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "bb9c941a-aa50-4b17-aef4-4283ef5ec08c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Full prunned model w/ tuning:  {'batch_time': 0.003432, 'loss': 14.100338, 'metric': 0.050777}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "warmup_torch_model(model, [(32, 1, 32, 400), (32, 50, 2)], device)\n",
    "print('Original model: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, alphabet, device=device)])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5Ijq4bAsUHa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684574807,
     "user_tz": -300,
     "elapsed": 14574,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "f9f00933-5b68-4230-c8f9-b118a31c59cd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original model:  {'batch_time': 0.003332, 'loss': 14.042188, 'metric': 0.049073}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results for full pruning\n",
    "\n",
    "* Original model: {'batch_time': 0.003332, 'loss': 14.042188, 'metric': 0.049073}\n",
    "* After pruning (w/o tuning): {'batch_time': 0.003171, 'loss': 16.876544, 'metric': 1.40559}\n",
    "* After pruning (w/ tuning): {'batch_time': 0.003432, 'loss': 14.100338, 'metric': 0.050777}"
   ],
   "metadata": {
    "id": "YR3RuDJ_X_o-",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Partial pruning (only convs)"
   ],
   "metadata": {
    "id": "HStFWOZnuaKb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_to_prune = deepcopy(model)\n",
    "\n",
    "model_to_prune.to('cpu')\n",
    "\n",
    "layers = get_layers_to_prune(model_to_prune)\n",
    "layers_to_prune = list(filter(lambda x: isinstance(x, (nn.Conv2d, nn.BatchNorm2d, nn.LSTM, nn.Linear)), layers))[:-2]\n",
    "layers_to_prune"
   ],
   "metadata": {
    "id": "iJhkw28iL1Iz",
    "pycharm": {
     "name": "#%%\n"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684574807,
     "user_tz": -300,
     "elapsed": 15,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f4694054-1acb-4c84-f1d9-d2170855f8c6"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same),\n",
       " BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " LSTM(258, 256, batch_first=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "prune_torch_model(layers_to_prune)"
   ],
   "metadata": {
    "id": "16uQlUeduh9D",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684574808,
     "user_tz": -300,
     "elapsed": 15,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "summary(model_to_prune, input_size=[(32, 1, 32, 400), (32, 50, 2)], device=device, depth=1)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeXjWOiuujlG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684574808,
     "user_tz": -300,
     "elapsed": 14,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "4b791e1f-82b0-4e9b-f1b8-4c532190935e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CRNN                                     [32, 50, 46]              --\n",
       "├─Sequential: 1-1                        [32, 231, 1, 50]          348,867\n",
       "├─LSTM: 1-2                              [32, 50, 256]             502,784\n",
       "├─LSTM: 1-3                              [32, 50, 256]             526,336\n",
       "├─Sequential: 1-4                        [32, 50, 46]              11,822\n",
       "==========================================================================================\n",
       "Total params: 1,389,809\n",
       "Trainable params: 1,389,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 6.42\n",
       "==========================================================================================\n",
       "Input size (MB): 1.65\n",
       "Forward/backward pass size (MB): 375.32\n",
       "Params size (MB): 5.56\n",
       "Estimated Total Size (MB): 382.53\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "warmup_torch_model(model_to_prune, [(32, 1, 32, 400), (32, 50, 2)], device)\n",
    "print('Partial prunned model w/o tuning: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model_to_prune, val_loader, alphabet, device=device)])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTBbIIhruq_M",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684589043,
     "user_tz": -300,
     "elapsed": 14248,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "822bc5c5-2122-4776-805d-bf012fbaec91",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Partial prunned model w/o tuning:  {'batch_time': 0.003353, 'loss': 14.052087, 'metric': 0.055323}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "best_state, _ = train_model(model_to_prune,  alphabet, 2, train_loader, val_loader, lr=5e-4, device=device)\n",
    "model_to_prune.load_state_dict(best_state)\n",
    "print('Partial prunned model w/ tuning: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model_to_prune, val_loader, alphabet, device=device)])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgbHjd7_ulfA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684661293,
     "user_tz": -300,
     "elapsed": 72261,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "6b217ca2-27f9-403b-d41c-3bc1655ac2d3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0, 103/103, loss: 0.217662, cer: 0.038555, val_loss: 3.066838, val_cer: 0.104845\n",
      "Epoch 1, 103/103, loss: 0.142083, cer: 0.037157, val_loss: 3.587152, val_cer: 0.116859\n",
      "Partial prunned model w/ tuning:  {'batch_time': 0.003161, 'loss': 14.0428, 'metric': 0.049154}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "warmup_torch_model(model, [(32, 1, 32, 400), (32, 50, 2)], device)\n",
    "print('Original model: ', dict(zip(['batch_time', 'loss', 'metric'], [round(e, 6) for e in validate_model(model, val_loader, alphabet, device=device)])))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVz7nMIZus6g",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684675803,
     "user_tz": -300,
     "elapsed": 14522,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "outputId": "9042382d-989b-4c63-8872-9f29778d94c8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original model:  {'batch_time': 0.003282, 'loss': 14.042188, 'metric': 0.049073}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results for partial pruning\n",
    "\n",
    "* Original model: {'batch_time': 0.003282, 'loss': 14.042188, 'metric': 0.049073}\n",
    "* After pruning (w/o tuning): {'batch_time': 0.003353, 'loss': 14.052087, 'metric': 0.055323}\n",
    "* After pruning (w/ tuning): {'batch_time': 0.003161, 'loss': 14.0428, 'metric': 0.049154}"
   ],
   "metadata": {
    "id": "bl0MEyhsu5zy",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Overall results\n",
    "\n",
    "<pre>\n",
    "+---------------------------------+-------------+-------------+-------------+------------+\n",
    "|      Model                      | #Params     |   Val loss  | Val CER     | Batch time |\n",
    "+---------------------------------+-------------+-------------+-------------+------------+\n",
    "| Original model                  | 1.492M      | 14.042188   | 0.049073    | 0.003332   |\n",
    "+---------------------------------+-------------+-------------+-------------+------------+\n",
    "| Full pruning (before tuning)    | 1.219M      | 16.876544   | 1.40559     | 0.003171   |\n",
    "+---------------------------------+-------------+-------------+-------------+------------+\n",
    "| Full pruning (after tuning)     | 1.219M      | 14.100338   | 0.050777    | 0.003432   |\n",
    "+---------------------------------+-------------+-------------+-------------+------------+\n",
    "| Partial pruning (before tuning) | 1.389M      | 14.052087   | 0.055323    | 0.003353   |\n",
    "+---------------------------------+-------------+-------------+-------------+------------+\n",
    "| Partial pruning (after tuning)  | 1.389M      | 14.0428     | 0.049154    | 0.003161   |\n",
    "+---------------------------------+-------------+-------------+-------------+------------+\n",
    "</pre>"
   ],
   "metadata": {
    "id": "Fuiig1CMSikA",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, partial pruning looks better (due to lower net stress). Reccurent part doesn't have to restructure hidden size vecor as its dimension persists unchanged"
   ],
   "metadata": {
    "id": "V6LBz8K-vEBb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "WBONb9ZTuuHC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1698684675804,
     "user_tz": -300,
     "elapsed": 14,
     "user": {
      "displayName": "Petr Ivanov",
      "userId": "15588216699611977235"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  }
 ]
}